Sprint 1 : (22 Oct, 2024 - 31 Oct, 2024)

1. [] Implement Vector Database
2. [] Implement Context Search
3. [] Implement Similar Search
4. [] Modify the generate function which will only take the current message and automatically pass most common context of the current chat session along with the message so the ai response become more accurate and for local llm (don't have to worry to much regarding the token size)
5. [] Implement Whole Chat Sessions logic 
6. [] Implement Proper Store and apis for Chat History, linking between different chats on context search

Sprint 2 : Upcomming
1. [] Implement PDF Querying | embeddings | so on
2. [] Implement Image Analysis AIPs | (check whether llama) can also do the thing or not